import sys
!{sys.executable} -m pip install --upgrade aequitas pandas numpy seaborn matplotlib altair


import pandas as pd
from aequitas.group import Group
from aequitas.bias import Bias
from aequitas.fairness import Fairness
import aequitas.plot as ap

# Enable Pandas to display dataframes without restriction.
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)


# Load in the data and take an initial look at it.
df = pd.read_csv("data/compas_for_aequitas.csv")
print(df.shape)
df.head()


# Race is our protected class that we will be exploring.
df["race"].value_counts()


# Remove the races that have very little data in this data.
df = df[~df["race"].isin(["Asian", "Native American"])]





group = Group()
xtab, _ = group.get_crosstabs(df)

xtab.head(10)








bias = Bias()
bias_df = bias.get_disparity_predefined_groups(xtab,
                                               original_df=df,
                                               ref_groups_dict={"race": "Caucasian", "sex": "Male", "age_cat": "25 - 45"},
                                               alpha=0.05,
                                               mask_significance=True)
bias_df.head(10)





bias.get_disparity_major_group(xtab,
                               original_df=df,
                               alpha=0.05,
                               mask_significance=True).head(10)


fairness = Fairness()
fairness_df = fairness.get_group_value_fairness(bias_df)
fairness_df.head(10)


overall_fairness = fairness.get_overall_fairness(fairness_df)
print(overall_fairness)


metrics = ['fpr', 'fnr', 'for']
disparity_tolerance = 1.25

ap.summary(bias_df, metrics, fairness_threshold=disparity_tolerance)



